#!/usr/bin/env python3
"""
æµ‹è¯•å“åº”æ—¶é—´ä¼˜åŒ–æ•ˆæœ

éªŒè¯è¿›åº¦æç¤ºå’Œæ€§èƒ½ä¼˜åŒ–æ˜¯å¦æœ‰æ•ˆã€‚
"""

import sys
import os
import time
import logging
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from qcli_api_service.services.qcli_service import qcli_service

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_progress_indicators():
    """æµ‹è¯•è¿›åº¦æç¤ºåŠŸèƒ½"""
    logger.info("=== æµ‹è¯•è¿›åº¦æç¤ºåŠŸèƒ½ ===")
    
    try:
        message = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹AWS Lambdaã€‚"
        
        logger.info("å¼€å§‹æµå¼å¯¹è¯ï¼Œè§‚å¯Ÿè¿›åº¦æç¤º...")
        start_time = time.time()
        
        chunks = []
        chunk_times = []
        
        for i, chunk in enumerate(qcli_service.stream_chat(message)):
            current_time = time.time()
            elapsed = current_time - start_time
            
            chunks.append(chunk)
            chunk_times.append(elapsed)
            
            logger.info(f"æ”¶åˆ°ç¬¬{i+1}ä¸ªæ•°æ®å— (è€—æ—¶: {elapsed:.2f}ç§’): {chunk[:50]}...")
            
            # å¦‚æœæ˜¯å‰å‡ ä¸ªå—ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«è¿›åº¦æç¤º
            if i < 3:
                if "æ­£åœ¨å¤„ç†" in chunk or "æ­£åœ¨æ€è€ƒ" in chunk or "ğŸ¤–" in chunk or "ğŸ”„" in chunk:
                    logger.info(f"  âœ… æ£€æµ‹åˆ°è¿›åº¦æç¤º")
        
        total_time = time.time() - start_time
        logger.info(f"âœ… æµå¼å¯¹è¯å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"   æ€»å…±æ”¶åˆ° {len(chunks)} ä¸ªæ•°æ®å—")
        logger.info(f"   é¦–ä¸ªæ•°æ®å—è€—æ—¶: {chunk_times[0]:.2f}ç§’")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿›åº¦æç¤º
        has_progress = any("æ­£åœ¨å¤„ç†" in chunk or "æ­£åœ¨æ€è€ƒ" in chunk for chunk in chunks[:3])
        if has_progress:
            logger.info("   âœ… è¿›åº¦æç¤ºåŠŸèƒ½æ­£å¸¸")
            return True
        else:
            logger.warning("   âš ï¸ æœªæ£€æµ‹åˆ°è¿›åº¦æç¤º")
            return False
            
    except Exception as e:
        logger.error(f"âŒ è¿›åº¦æç¤ºæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_output_processing_performance():
    """æµ‹è¯•è¾“å‡ºå¤„ç†æ€§èƒ½"""
    logger.info("=== æµ‹è¯•è¾“å‡ºå¤„ç†æ€§èƒ½ ===")
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„é‡å¤å†…å®¹
    test_content = """
    æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š
    â€¢ ç®¡ç†å’ŒæŸ¥è¯¢ AWS èµ„æº
    â€¢ æ‰§è¡Œå‘½ä»¤è¡Œæ“ä½œ
    â€¢ è¯»å†™æ–‡ä»¶å’Œç›®å½•
    â€¢ ç¼–å†™å’Œè°ƒè¯•ä»£ç 
    â€¢ æä¾› AWS æœ€ä½³å®è·µå»ºè®®
    â€¢ è§£å†³æŠ€æœ¯é—®é¢˜
    
    è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ
    
    æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š
    â€¢ ç®¡ç†å’ŒæŸ¥è¯¢ AWS èµ„æº
    â€¢ æ‰§è¡Œå‘½ä»¤è¡Œæ“ä½œ
    â€¢ è¯»å†™æ–‡ä»¶å’Œç›®å½•
    â€¢ ç¼–å†™å’Œè°ƒè¯•ä»£ç 
    â€¢ æä¾› AWS æœ€ä½³å®è·µå»ºè®®
    â€¢ è§£å†³æŠ€æœ¯é—®é¢˜
    
    è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ
    """
    
    try:
        # æµ‹è¯•ä¼˜åŒ–åçš„æ¸…ç†æ€§èƒ½
        start_time = time.time()
        
        cleaned_content = qcli_service._remove_duplicate_content(test_content)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        logger.info(f"âœ… è¾“å‡ºå¤„ç†å®Œæˆ")
        logger.info(f"   å¤„ç†æ—¶é—´: {processing_time:.4f}ç§’")
        logger.info(f"   åŸå§‹é•¿åº¦: {len(test_content)} å­—ç¬¦")
        logger.info(f"   æ¸…ç†åé•¿åº¦: {len(cleaned_content)} å­—ç¬¦")
        logger.info(f"   å‹ç¼©ç‡: {(1 - len(cleaned_content)/len(test_content))*100:.1f}%")
        
        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®å»é™¤äº†é‡å¤å†…å®¹
        lines = cleaned_content.split('\n')
        help_lines = [line for line in lines if "æˆ‘å¯ä»¥å¸®åŠ©æ‚¨" in line]
        
        if len(help_lines) <= 1:
            logger.info("   âœ… é‡å¤å†…å®¹å·²æ­£ç¡®ç§»é™¤")
            return True
        else:
            logger.warning(f"   âš ï¸ ä»æœ‰ {len(help_lines)} è¡Œé‡å¤å†…å®¹")
            return False
            
    except Exception as e:
        logger.error(f"âŒ è¾“å‡ºå¤„ç†æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def benchmark_response_times():
    """åŸºå‡†æµ‹è¯•å“åº”æ—¶é—´"""
    logger.info("=== åŸºå‡†æµ‹è¯•å“åº”æ—¶é—´ ===")
    
    test_cases = [
        ("ç®€å•é—®å€™", "ä½ å¥½"),
        ("çŸ­é—®é¢˜", "ä»€ä¹ˆæ˜¯AWS?"),
        ("ä¸­ç­‰é—®é¢˜", "è¯·è§£é‡Šä¸€ä¸‹Amazon S3çš„ä¸»è¦åŠŸèƒ½ã€‚")
    ]
    
    results = []
    
    for test_name, message in test_cases:
        logger.info(f"--- æµ‹è¯•: {test_name} ---")
        
        try:
            start_time = time.time()
            
            # ä½¿ç”¨éæµå¼æ–¹æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•
            response = qcli_service.chat(message)
            
            end_time = time.time()
            duration = end_time - start_time
            
            results.append({
                'test_name': test_name,
                'duration': duration,
                'response_length': len(response),
                'success': True
            })
            
            logger.info(f"âœ… {test_name} å®Œæˆ")
            logger.info(f"   è€—æ—¶: {duration:.2f}ç§’")
            logger.info(f"   å›å¤é•¿åº¦: {len(response)} å­—ç¬¦")
            logger.info(f"   å¤„ç†é€Ÿåº¦: {len(response)/duration:.1f} å­—ç¬¦/ç§’")
            
        except Exception as e:
            logger.error(f"âŒ {test_name} å¤±è´¥: {e}")
            results.append({
                'test_name': test_name,
                'duration': 0,
                'response_length': 0,
                'success': False
            })
    
    # åˆ†æç»“æœ
    logger.info("=== æ€§èƒ½åˆ†æ ===")
    successful_tests = [r for r in results if r['success']]
    
    if successful_tests:
        avg_duration = sum(r['duration'] for r in successful_tests) / len(successful_tests)
        avg_speed = sum(r['response_length']/r['duration'] for r in successful_tests) / len(successful_tests)
        
        logger.info(f"å¹³å‡å“åº”æ—¶é—´: {avg_duration:.2f}ç§’")
        logger.info(f"å¹³å‡å¤„ç†é€Ÿåº¦: {avg_speed:.1f} å­—ç¬¦/ç§’")
        
        # ä¸ä¹‹å‰çš„åŸºçº¿æ¯”è¾ƒ
        baseline_times = {
            "ç®€å•é—®å€™": 9.7,
            "çŸ­é—®é¢˜": 11.3,
            "ä¸­ç­‰é—®é¢˜": 18.3
        }
        
        for result in successful_tests:
            test_name = result['test_name']
            if test_name in baseline_times:
                baseline = baseline_times[test_name]
                current = result['duration']
                improvement = (baseline - current) / baseline * 100
                
                if improvement > 0:
                    logger.info(f"{test_name}: æ€§èƒ½æå‡ {improvement:.1f}%")
                else:
                    logger.info(f"{test_name}: æ€§èƒ½ä¸‹é™ {abs(improvement):.1f}%")
    
    return results

def test_streaming_experience():
    """æµ‹è¯•æµå¼ä½“éªŒ"""
    logger.info("=== æµ‹è¯•æµå¼ä½“éªŒ ===")
    
    try:
        message = "è¯·è¯¦ç»†è§£é‡ŠAWS Lambdaçš„å·¥ä½œåŸç†ã€‚"
        
        logger.info("æµ‹è¯•æµå¼å“åº”çš„ç”¨æˆ·ä½“éªŒ...")
        start_time = time.time()
        
        first_chunk_time = None
        meaningful_content_time = None
        chunks_received = 0
        
        for chunk in qcli_service.stream_chat(message):
            current_time = time.time()
            elapsed = current_time - start_time
            chunks_received += 1
            
            if first_chunk_time is None:
                first_chunk_time = elapsed
                logger.info(f"é¦–ä¸ªæ•°æ®å—è€—æ—¶: {elapsed:.2f}ç§’")
            
            # æ£€æµ‹åˆ°æœ‰æ„ä¹‰çš„å†…å®¹ï¼ˆéè¿›åº¦æç¤ºï¼‰
            if (meaningful_content_time is None and 
                "æ­£åœ¨å¤„ç†" not in chunk and "æ­£åœ¨æ€è€ƒ" not in chunk and 
                len(chunk.strip()) > 20):
                meaningful_content_time = elapsed
                logger.info(f"é¦–ä¸ªæœ‰æ„ä¹‰å†…å®¹è€—æ—¶: {elapsed:.2f}ç§’")
            
            if chunks_received <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªå—çš„è¯¦æƒ…
                logger.info(f"æ•°æ®å— {chunks_received} ({elapsed:.2f}s): {chunk[:30]}...")
        
        total_time = time.time() - start_time
        
        logger.info(f"âœ… æµå¼å“åº”å®Œæˆ")
        logger.info(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"   é¦–ä¸ªæ•°æ®å—: {first_chunk_time:.2f}ç§’")
        logger.info(f"   é¦–ä¸ªæœ‰æ„ä¹‰å†…å®¹: {meaningful_content_time:.2f}ç§’")
        logger.info(f"   æ€»æ•°æ®å—æ•°: {chunks_received}")
        
        # è¯„ä¼°ç”¨æˆ·ä½“éªŒ
        if first_chunk_time and first_chunk_time < 1.0:
            logger.info("   âœ… å“åº”åŠæ—¶ï¼Œç”¨æˆ·ä½“éªŒè‰¯å¥½")
            return True
        else:
            logger.warning("   âš ï¸ é¦–ä¸ªå“åº”è¾ƒæ…¢ï¼Œç”¨æˆ·ä½“éªŒä¸€èˆ¬")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµå¼ä½“éªŒæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹æµ‹è¯•å“åº”æ—¶é—´ä¼˜åŒ–æ•ˆæœ")
    logger.info("=" * 50)
    
    # æµ‹è¯•ç»“æœç»Ÿè®¡
    tests = []
    
    # 1. æµ‹è¯•è¿›åº¦æç¤º
    tests.append(("è¿›åº¦æç¤ºåŠŸèƒ½", test_progress_indicators()))
    
    # 2. æµ‹è¯•è¾“å‡ºå¤„ç†æ€§èƒ½
    tests.append(("è¾“å‡ºå¤„ç†æ€§èƒ½", test_output_processing_performance()))
    
    # 3. åŸºå‡†æµ‹è¯•å“åº”æ—¶é—´
    benchmark_results = benchmark_response_times()
    benchmark_success = all(r['success'] for r in benchmark_results)
    tests.append(("å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•", benchmark_success))
    
    # 4. æµ‹è¯•æµå¼ä½“éªŒ
    tests.append(("æµå¼ä½“éªŒ", test_streaming_experience()))
    
    # ç»Ÿè®¡ç»“æœ
    logger.info("=" * 50)
    logger.info("æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = 0
    total = len(tests)
    
    for test_name, result in tests:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"æ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å“åº”æ—¶é—´ä¼˜åŒ–æˆåŠŸã€‚")
    else:
        logger.warning(f"âš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚")

if __name__ == "__main__":
    main()